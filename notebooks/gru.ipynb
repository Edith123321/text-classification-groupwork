{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3374a610",
   "metadata": {},
   "source": [
    "# Gated Recurrent Unit (GRU) for SMS Spam Classification\n",
    "\n",
    "This notebook trains and evaluates a GRU model with bidirectional layers for SMS spam detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfcf4e7",
   "metadata": {},
   "source": [
    "## GRU Model for SMS Spam Detection\n",
    " **Student:** Edith Githinji\n",
    " **Model:** GRU (Gated Recurrent Unit)\n",
    " **Embeddings Tested:** TF-IDF, Skip-gram, CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cc0538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "# Machine learning imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TensorFlow imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, GRU, Dense, Dropout, Bidirectional, GlobalMaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6ad7d5",
   "metadata": {},
   "source": [
    "### 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "924c875e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded 5572 messages\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_path = \"../data/sms+spam+collection/SMSSpamCollection\"\n",
    "try:\n",
    "    df = pd.read_csv(data_path, sep='\\t', names=['label', 'message'])\n",
    "    print(f\" Successfully loaded {len(df)} messages\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading data: {e}\")\n",
    "    # Try alternative path\n",
    "    data_path = \"data/sms+spam+collection/SMSSpamCollection\"\n",
    "    df = pd.read_csv(data_path, sep='\\t', names=['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0997d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dataset Info:\n",
      "Shape: (5572, 2)\n",
      "Columns: ['label', 'message']\n",
      "\n",
      " Class Distribution:\n",
      "label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Spam percentage: 13.41%\n",
      "\n",
      " Sample Messages:\n",
      "  label                                            message\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "# Display basic info\n",
    "print(\"\\n Dataset Info:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\n Class Distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "print(f\"\\nSpam percentage: {(df['label'] == 'spam').mean():.2%}\")\n",
    "\n",
    "# Show samples\n",
    "print(\"\\n Sample Messages:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0968884c",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Preprocess Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e38675c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned sample:\n",
      "                                             message  \\\n",
      "0  Go until jurong point, crazy.. Available only ...   \n",
      "1                      Ok lar... Joking wif u oni...   \n",
      "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
      "3  U dun say so early hor... U c already then say...   \n",
      "4  Nah I don't think he goes to usf, he lives aro...   \n",
      "\n",
      "                                       clean_message label  label_binary  \n",
      "0  go until jurong point crazy available only in ...   ham             0  \n",
      "1                            ok lar joking wif u oni   ham             0  \n",
      "2  free entry in a wkly comp to win fa cup final ...  spam             1  \n",
      "3        u dun say so early hor u c already then say   ham             0  \n",
      "4  nah i dont think he goes to usf he lives aroun...   ham             0  \n"
     ]
    }
   ],
   "source": [
    "# Simple text cleaning function\n",
    "def clean_text(text):\n",
    "    \"\"\"Basic text cleaning\"\"\"\n",
    "    import re\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "df['clean_message'] = df['message'].apply(clean_text)\n",
    "\n",
    "# Convert labels to binary (0=ham, 1=spam)\n",
    "df['label_binary'] = df['label'].apply(lambda x: 1 if x == 'spam' else 0)\n",
    "\n",
    "# Check cleaned data\n",
    "print(\"Cleaned sample:\")\n",
    "print(df[['message', 'clean_message', 'label', 'label_binary']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a072cce",
   "metadata": {},
   "source": [
    "## 4. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5098553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data Split:\n",
      "Train: 3342 samples (60.0%)\n",
      "Validation: 1115 samples (20.0%)\n",
      "Test: 1115 samples (20.0%)\n",
      "\n",
      " Class Balance in Train: {0: 2894, 1: 448}\n"
     ]
    }
   ],
   "source": [
    "# Paths to processed split files\n",
    "train_path = \"../data/processed/train.tsv\"\n",
    "val_path   = \"../data/processed/val.tsv\"\n",
    "test_path  = \"../data/processed/test.tsv\"\n",
    "\n",
    "# Load the splits\n",
    "train_df = pd.read_csv(train_path, sep='\\t', names=['label', 'message'])\n",
    "val_df   = pd.read_csv(val_path, sep='\\t', names=['label', 'message'])\n",
    "test_df  = pd.read_csv(test_path, sep='\\t', names=['label', 'message'])\n",
    "\n",
    "# Clean the messages\n",
    "for df_split in [train_df, val_df, test_df]:\n",
    "    df_split['clean_message'] = df_split['message'].apply(clean_text)\n",
    "    df_split['label_binary'] = df_split['label'].apply(lambda x: 1 if x == 'spam' else 0)\n",
    "\n",
    "# Extract features and labels\n",
    "X_train, y_train = train_df['clean_message'].values, train_df['label_binary'].values\n",
    "X_val, y_val     = val_df['clean_message'].values, val_df['label_binary'].values\n",
    "X_test, y_test   = test_df['clean_message'].values, test_df['label_binary'].values\n",
    "\n",
    "# Print data info\n",
    "print(f\"Train samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "\n",
    "# Check class balance in train\n",
    "print(f\"\\nClass balance in Train: {pd.Series(y_train).value_counts().to_dict()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a25aae7",
   "metadata": {},
   "source": [
    "## 5. GRU Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1f46ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gru_model(vocab_size, embedding_dim=100, hidden_dim=128, \n",
    "                    num_layers=2, dropout_rate=0.5, max_len=100,\n",
    "                    embedding_matrix=None):\n",
    "    \"\"\"\n",
    "    Create a GRU-based spam classifier\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(max_len,))\n",
    "    \n",
    "    # Embedding layer\n",
    "    if embedding_matrix is not None:\n",
    "        embedding_layer = Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=embedding_matrix.shape[1],\n",
    "            weights=[embedding_matrix],\n",
    "            input_length=max_len,\n",
    "            trainable=False  # Can be True to fine-tune\n",
    "        )(inputs)\n",
    "    else:\n",
    "        embedding_layer = Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=embedding_dim,\n",
    "            input_length=max_len\n",
    "        )(inputs)\n",
    "    \n",
    "    # Add dropout to embeddings\n",
    "    x = Dropout(dropout_rate)(embedding_layer)\n",
    "    \n",
    "    # Stack multiple GRU layers\n",
    "    for i in range(num_layers):\n",
    "        return_sequences = (i < num_layers - 1)  # Return sequences for all but last layer\n",
    "        gru_layer = Bidirectional(GRU(hidden_dim, return_sequences=return_sequences, dropout=dropout_rate))\n",
    "        x = gru_layer(x)\n",
    "        if return_sequences:\n",
    "            x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # Classifier\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(dropout_rate/2)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2a3a03",
   "metadata": {},
   "source": [
    "## 6. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3732c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(texts, tokenizer, max_len=100):\n",
    "    \"\"\"Convert texts to padded sequences\"\"\"\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    padded = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "    return padded\n",
    "\n",
    "def build_tokenizer(texts, max_words=10000):\n",
    "    \"\"\"Build tokenizer from texts\"\"\"\n",
    "    tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    \n",
    "    vocab_size = min(max_words, len(tokenizer.word_index) + 1)\n",
    "    print(f\"Vocabulary size: {vocab_size}\")\n",
    "    print(f\"Most common words: {list(tokenizer.word_index.keys())[:10]}\")\n",
    "    \n",
    "    return tokenizer, vocab_size\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    \"\"\"Evaluate model and return metrics\"\"\"\n",
    "    predictions = (model.predict(X, verbose=0) > 0.5).astype(int)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y, predictions),\n",
    "        'f1': f1_score(y, predictions),\n",
    "        'precision': precision_score(y, predictions),\n",
    "        'recall': recall_score(y, predictions)\n",
    "    }\n",
    "    \n",
    "    return metrics, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be292faa",
   "metadata": {},
   "source": [
    "## EXPERIMENT 1: GRU with TF-IDF Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccab41a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPERIMENT 1: GRU with TF-IDF Embeddings\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT 1: GRU with TF-IDF Embeddings\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79575d51",
   "metadata": {},
   "source": [
    "### 7.1 Prepare TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c86c6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 6417\n",
      "Most common words: ['<OOV>', 'to', 'i', 'you', 'a', 'the', 'u', 'and', 'in', 'is']\n",
      "Sequence shape - Train: (3342, 100)\n"
     ]
    }
   ],
   "source": [
    "# Build tokenizer\n",
    "tokenizer_tfidf, vocab_size_tfidf = build_tokenizer(X_train)\n",
    "\n",
    "# Prepare sequences\n",
    "max_len = 100\n",
    "X_train_seq = prepare_sequences(X_train, tokenizer_tfidf, max_len)\n",
    "X_val_seq = prepare_sequences(X_val, tokenizer_tfidf, max_len)\n",
    "X_test_seq = prepare_sequences(X_test, tokenizer_tfidf, max_len)\n",
    "\n",
    "print(f\"Sequence shape - Train: {X_train_seq.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f667e27",
   "metadata": {},
   "source": [
    "### 7.2 Train GRU with TF-IDF Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9f739f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training GRU with TF-IDF context...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sola/.local/share/virtualenvs/text-classification-groupwork-ObVFzkD4/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:100: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">641,700</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">176,640</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">296,448</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       â”‚       \u001b[38;5;34m641,700\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚       \u001b[38;5;34m176,640\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚       \u001b[38;5;34m296,448\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m16,448\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m65\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,131,301</span> (4.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,131,301\u001b[0m (4.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,131,301</span> (4.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,131,301\u001b[0m (4.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8322 - loss: 0.4656"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sola/.local/share/virtualenvs/text-classification-groupwork-ObVFzkD4/lib/python3.12/site-packages/keras/src/callbacks/model_checkpoint.py:276: UserWarning: Can save best model only with val_f1 available.\n",
      "  if self._should_save_model(epoch, batch, logs, filepath):\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 187ms/step - accuracy: 0.8770 - loss: 0.3442 - val_accuracy: 0.9489 - val_loss: 0.1458 - learning_rate: 0.0010\n",
      "Epoch 2/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9746 - loss: 0.0836"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 195ms/step - accuracy: 0.9764 - loss: 0.0770 - val_accuracy: 0.9776 - val_loss: 0.0822 - learning_rate: 0.0010\n",
      "Epoch 3/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.9900 - loss: 0.0350"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 281ms/step - accuracy: 0.9892 - loss: 0.0380 - val_accuracy: 0.9686 - val_loss: 0.1120 - learning_rate: 0.0010\n",
      "Epoch 4/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.9921 - loss: 0.0286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 291ms/step - accuracy: 0.9928 - loss: 0.0274 - val_accuracy: 0.9785 - val_loss: 0.0979 - learning_rate: 0.0010\n",
      "Epoch 5/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.9964 - loss: 0.0175"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 290ms/step - accuracy: 0.9949 - loss: 0.0196 - val_accuracy: 0.9785 - val_loss: 0.0930 - learning_rate: 5.0000e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.9977 - loss: 0.0121"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 293ms/step - accuracy: 0.9970 - loss: 0.0122 - val_accuracy: 0.9821 - val_loss: 0.0885 - learning_rate: 5.0000e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.9984 - loss: 0.0081"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 292ms/step - accuracy: 0.9979 - loss: 0.0084 - val_accuracy: 0.9776 - val_loss: 0.0999 - learning_rate: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "vocab_size = vocab_size_tfidf\n",
    "embedding_dim = 100\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "dropout_rate = 0.5\n",
    "\n",
    "# Create model\n",
    "model_tfidf = create_gru_model(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=num_layers,\n",
    "    dropout_rate=dropout_rate,\n",
    "    max_len=max_len,\n",
    "    embedding_matrix=None\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "model_tfidf.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2),\n",
    "    ModelCheckpoint('best_model_tfidf.h5', monitor='val_f1', \n",
    "                    save_best_only=True, mode='max')\n",
    "]\n",
    "\n",
    "print(\"\\n Training GRU with TF-IDF context...\")\n",
    "print(model_tfidf.summary())\n",
    "\n",
    "# Train model\n",
    "history_tfidf = model_tfidf.fit(\n",
    "    X_train_seq, y_train,\n",
    "    validation_data=(X_val_seq, y_val),\n",
    "    epochs=15,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f6c01b",
   "metadata": {},
   "source": [
    "## 7.3 Evaluate TF-IDF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "21de5119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TF-IDF Model - Test Results:\n",
      "Accuracy:  0.9794\n",
      "F1 Score:  0.9193\n",
      "Precision: 0.9632\n",
      "Recall:    0.8792\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib_inline'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Create confusion matrix\u001b[39;00m\n\u001b[32m     17\u001b[39m cm_tfidf = confusion_matrix(y_test, preds_tfidf)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigsize\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m sns.heatmap(cm_tfidf, annot=\u001b[38;5;28;01mTrue\u001b[39;00m, fmt=\u001b[33m'\u001b[39m\u001b[33md\u001b[39m\u001b[33m'\u001b[39m, cmap=\u001b[33m'\u001b[39m\u001b[33mBlues\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     20\u001b[39m             xticklabels=[\u001b[33m'\u001b[39m\u001b[33mHam\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mSpam\u001b[39m\u001b[33m'\u001b[39m], yticklabels=[\u001b[33m'\u001b[39m\u001b[33mHam\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mSpam\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     21\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mConfusion Matrix - GRU with TF-IDF\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/text-classification-groupwork-ObVFzkD4/lib/python3.12/site-packages/matplotlib/pyplot.py:1041\u001b[39m, in \u001b[36mfigure\u001b[39m\u001b[34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, clear, **kwargs)\u001b[39m\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(allnums) == max_open_warning >= \u001b[32m1\u001b[39m:\n\u001b[32m   1032\u001b[39m     _api.warn_external(\n\u001b[32m   1033\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMore than \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_open_warning\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m figures have been opened. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1034\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFigures created through the pyplot interface \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1038\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConsider using `matplotlib.pyplot.close()`.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1039\u001b[39m         \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1041\u001b[39m manager = \u001b[43mnew_figure_manager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfigsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1043\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframeon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframeon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[43m    \u001b[49m\u001b[43mFigureClass\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFigureClass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1045\u001b[39m fig = manager.canvas.figure\n\u001b[32m   1046\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fig_label:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/text-classification-groupwork-ObVFzkD4/lib/python3.12/site-packages/matplotlib/pyplot.py:550\u001b[39m, in \u001b[36mnew_figure_manager\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_figure_manager\u001b[39m(*args, **kwargs):\n\u001b[32m    549\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a new figure manager instance.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m     \u001b[43m_warn_if_gui_out_of_main_thread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_backend_mod().new_figure_manager(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/text-classification-groupwork-ObVFzkD4/lib/python3.12/site-packages/matplotlib/pyplot.py:527\u001b[39m, in \u001b[36m_warn_if_gui_out_of_main_thread\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_warn_if_gui_out_of_main_thread\u001b[39m() -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    526\u001b[39m     warn = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m527\u001b[39m     canvas_class = cast(\u001b[38;5;28mtype\u001b[39m[FigureCanvasBase], \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.FigureCanvas)\n\u001b[32m    528\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m canvas_class.required_interactive_framework:\n\u001b[32m    529\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(threading, \u001b[33m'\u001b[39m\u001b[33mget_native_id\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    530\u001b[39m             \u001b[38;5;66;03m# This compares native thread ids because even if Python-level\u001b[39;00m\n\u001b[32m    531\u001b[39m             \u001b[38;5;66;03m# Thread objects match, the underlying OS thread (which is what\u001b[39;00m\n\u001b[32m    532\u001b[39m             \u001b[38;5;66;03m# really matters) may be different on Python implementations with\u001b[39;00m\n\u001b[32m    533\u001b[39m             \u001b[38;5;66;03m# green threads.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/text-classification-groupwork-ObVFzkD4/lib/python3.12/site-packages/matplotlib/pyplot.py:368\u001b[39m, in \u001b[36m_get_backend_mod\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    360\u001b[39m \u001b[33;03mEnsure that a backend is selected and return it.\u001b[39;00m\n\u001b[32m    361\u001b[39m \n\u001b[32m    362\u001b[39m \u001b[33;03mThis is currently private, but may be made public in the future.\u001b[39;00m\n\u001b[32m    363\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _backend_mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    365\u001b[39m     \u001b[38;5;66;03m# Use rcParams._get(\"backend\") to avoid going through the fallback\u001b[39;00m\n\u001b[32m    366\u001b[39m     \u001b[38;5;66;03m# logic (which will (re)import pyplot and then call switch_backend if\u001b[39;00m\n\u001b[32m    367\u001b[39m     \u001b[38;5;66;03m# we need to resolve the auto sentinel)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m     \u001b[43mswitch_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrcParams\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackend\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[38;5;28mtype\u001b[39m[matplotlib.backend_bases._Backend], _backend_mod)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/text-classification-groupwork-ObVFzkD4/lib/python3.12/site-packages/matplotlib/pyplot.py:424\u001b[39m, in \u001b[36mswitch_backend\u001b[39m\u001b[34m(newbackend)\u001b[39m\n\u001b[32m    421\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    422\u001b[39m old_backend = rcParams._get(\u001b[33m'\u001b[39m\u001b[33mbackend\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# get without triggering backend resolution\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m module = \u001b[43mbackend_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_backend_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m canvas_class = module.FigureCanvas\n\u001b[32m    427\u001b[39m required_framework = canvas_class.required_interactive_framework\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/text-classification-groupwork-ObVFzkD4/lib/python3.12/site-packages/matplotlib/backends/registry.py:317\u001b[39m, in \u001b[36mBackendRegistry.load_backend_module\u001b[39m\u001b[34m(self, backend)\u001b[39m\n\u001b[32m    303\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    304\u001b[39m \u001b[33;03mLoad and return the module containing the specified backend.\u001b[39;00m\n\u001b[32m    305\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    314\u001b[39m \u001b[33;03m    Module containing backend.\u001b[39;00m\n\u001b[32m    315\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    316\u001b[39m module_name = \u001b[38;5;28mself\u001b[39m._backend_module_name(backend)\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/importlib/__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     88\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1310\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:488\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1324\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib_inline'"
     ]
    }
   ],
   "source": [
    "test_metrics_tfidf, preds_tfidf = evaluate_model(model_tfidf, X_test_seq, y_test)\n",
    "\n",
    "print(\"\\n TF-IDF Model - Test Results:\")\n",
    "print(f\"Accuracy:  {test_metrics_tfidf['accuracy']:.4f}\")\n",
    "print(f\"F1 Score:  {test_metrics_tfidf['f1']:.4f}\")\n",
    "print(f\"Precision: {test_metrics_tfidf['precision']:.4f}\")\n",
    "print(f\"Recall:    {test_metrics_tfidf['recall']:.4f}\")\n",
    "\n",
    "# Save results\n",
    "results_tfidf = {\n",
    "    'embedding': 'TF-IDF',\n",
    "    'test_metrics': test_metrics_tfidf,\n",
    "    'train_history': history_tfidf.history\n",
    "}\n",
    "\n",
    "# Create confusion matrix\n",
    "cm_tfidf = confusion_matrix(y_test, preds_tfidf)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_tfidf, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "plt.title('Confusion Matrix - GRU with TF-IDF')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig('../results/figures/gru_tfidf_confusion.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e7b97b",
   "metadata": {},
   "source": [
    "## EXPERIMENT 2: GRU with Skip-gram Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da759b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXPERIMENT 2: GRU with Skip-gram Embeddings\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPERIMENT 2: GRU with Skip-gram Embeddings\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ac32b7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPERIMENT 2: GRU with Skip-gram Embeddings - Training Skip-gram\n",
      "============================================================\n",
      "âœ“ Skip-gram embedding matrix shape: (6417, 100)\n",
      "============================================================\n",
      "EXPERIMENT 2: GRU with Skip-gram Embeddings - Training Skip-gram\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Skip-gram embedding matrix shape: (6417, 100)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT 2: GRU with Skip-gram Embeddings - Training Skip-gram\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Prepare sentences\n",
    "sentences = [text.split() for text in all_texts]\n",
    "\n",
    "# Train Word2Vec skip-gram model\n",
    "skipgram_model = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    sg=1,  # sg=1 for skip-gram\n",
    "    workers=4,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# Create embedding matrix\n",
    "embedding_dim = 100\n",
    "embedding_matrix_skipgram = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "word_index = tokenizer_tfidf.word_index\n",
    "for word, idx in word_index.items():\n",
    "    if idx < vocab_size:\n",
    "        if word in skipgram_model.wv:\n",
    "            embedding_matrix_skipgram[idx] = skipgram_model.wv[word]\n",
    "        else:\n",
    "            # Initialize with small random values\n",
    "            embedding_matrix_skipgram[idx] = np.random.normal(scale=0.1, size=(embedding_dim,))\n",
    "\n",
    "print(f\"âœ“ Skip-gram embedding matrix shape: {embedding_matrix_skipgram.shape}\") \n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT 2: GRU with Skip-gram Embeddings - Training Skip-gram\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Prepare sentences\n",
    "sentences = [text.split() for text in all_texts]\n",
    "\n",
    "# Train Word2Vec skip-gram model\n",
    "skipgram_model = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    sg=1,  # sg=1 for skip-gram\n",
    "    workers=4,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# Create embedding matrix\n",
    "embedding_dim = 100\n",
    "embedding_matrix_skipgram = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "word_index = tokenizer_tfidf.word_index\n",
    "for word, idx in word_index.items():\n",
    "    if idx < vocab_size:\n",
    "        if word in skipgram_model.wv:\n",
    "            embedding_matrix_skipgram[idx] = skipgram_model.wv[word]\n",
    "        else:\n",
    "            # Initialize with small random values\n",
    "            embedding_matrix_skipgram[idx] = np.random.normal(scale=0.1, size=(embedding_dim,))\n",
    "\n",
    "print(f\"âœ“ Skip-gram embedding matrix shape: {embedding_matrix_skipgram.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881ae50a",
   "metadata": {},
   "source": [
    "### 8.2 Train GRU with Skip-gram Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1195a34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training GRU with Skip-gram embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sola/.local/share/virtualenvs/text-classification-groupwork-ObVFzkD4/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:100: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">641,700</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_10                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">176,640</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_11                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">296,448</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       â”‚       \u001b[38;5;34m641,700\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_10                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚       \u001b[38;5;34m176,640\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBidirectional\u001b[0m)                 â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_11                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚       \u001b[38;5;34m296,448\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBidirectional\u001b[0m)                 â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_10 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m16,448\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_11 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m65\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,131,301</span> (4.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,131,301\u001b[0m (4.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">489,601</span> (1.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m489,601\u001b[0m (1.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">641,700</span> (2.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m641,700\u001b[0m (2.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create model with skip-gram embeddings\n",
    "model_skipgram = create_gru_model(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_matrix_skipgram.shape[1],\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=num_layers,\n",
    "    dropout_rate=dropout_rate,\n",
    "    max_len=max_len,\n",
    "    embedding_matrix=embedding_matrix_skipgram\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "model_skipgram.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "callbacks_sg = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model_skipgram.h5', monitor='val_accuracy', \n",
    "                    save_best_only=True, mode='max')\n",
    "]\n",
    "\n",
    "print(\"\\n Training GRU with Skip-gram embeddings...\")\n",
    "print(model_skipgram.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597c8e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.8504 - loss: 0.4072"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 178ms/step - accuracy: 0.9010 - loss: 0.2853 - val_accuracy: 0.9695 - val_loss: 0.0974\n",
      "Epoch 2/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 183ms/step - accuracy: 0.9668 - loss: 0.1136 - val_accuracy: 0.9695 - val_loss: 0.0954\n",
      "Epoch 3/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 254ms/step - accuracy: 0.9704 - loss: 0.1028 - val_accuracy: 0.9686 - val_loss: 0.0929\n",
      "Epoch 4/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 239ms/step - accuracy: 0.9713 - loss: 0.0944 - val_accuracy: 0.9686 - val_loss: 0.1013\n",
      "Epoch 5/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 241ms/step - accuracy: 0.9704 - loss: 0.0905 - val_accuracy: 0.9686 - val_loss: 0.0948\n",
      "Epoch 6/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 249ms/step - accuracy: 0.9743 - loss: 0.0887 - val_accuracy: 0.9686 - val_loss: 0.1035\n",
      "Epoch 7/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 257ms/step - accuracy: 0.9701 - loss: 0.0886 - val_accuracy: 0.9695 - val_loss: 0.0985\n",
      "Epoch 8/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9733 - loss: 0.0982"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 265ms/step - accuracy: 0.9698 - loss: 0.0960 - val_accuracy: 0.9722 - val_loss: 0.0897\n",
      "Epoch 9/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 272ms/step - accuracy: 0.9737 - loss: 0.0828 - val_accuracy: 0.9695 - val_loss: 0.0942\n",
      "Epoch 10/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 268ms/step - accuracy: 0.9698 - loss: 0.0925 - val_accuracy: 0.9704 - val_loss: 0.0931\n",
      "Epoch 11/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 298ms/step - accuracy: 0.9743 - loss: 0.0851 - val_accuracy: 0.9659 - val_loss: 0.0940\n",
      "Epoch 12/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 270ms/step - accuracy: 0.9725 - loss: 0.0825 - val_accuracy: 0.9704 - val_loss: 0.0922\n",
      "Epoch 13/15\n",
      "\u001b[1m32/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 256ms/step - accuracy: 0.9788 - loss: 0.0754"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history_skipgram = model_skipgram.fit(\n",
    "    X_train_seq, y_train,\n",
    "    validation_data=(X_val_seq, y_val),\n",
    "    epochs=15,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks_sg,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e08c0b",
   "metadata": {},
   "source": [
    "### 8.3 Evaluate Skip-gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67d62b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_metrics_sg, preds_sg = evaluate_model(model_skipgram, X_test_seq, y_test)\n",
    "\n",
    "print(\"\\n Skip-gram Model - Test Results:\")\n",
    "print(f\"Accuracy:  {test_metrics_sg['accuracy']:.4f}\")\n",
    "print(f\"F1 Score:  {test_metrics_sg['f1']:.4f}\")\n",
    "print(f\"Precision: {test_metrics_sg['precision']:.4f}\")\n",
    "print(f\"Recall:    {test_metrics_sg['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854ef466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_skipgram = {\n",
    "    'embedding': 'Skip-gram',\n",
    "    'test_metrics': test_metrics_sg,\n",
    "    'train_history': history_skipgram.history\n",
    "}\n",
    "\n",
    "# Confusion matrix\n",
    "cm_sg = confusion_matrix(y_test, preds_sg)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_sg, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "plt.title('Confusion Matrix - GRU with Skip-gram')\n",
    "plt.savefig('../results/figures/gru_skipgram_confusion.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e26c49",
   "metadata": {},
   "source": [
    "## EXPERIMENT 3: GRU with CBOW Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0be104c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXPERIMENT 3: GRU with CBOW Embeddings\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPERIMENT 3: GRU with CBOW Embeddings\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7606e66",
   "metadata": {},
   "source": [
    "### 9.1 Train CBOW Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69175d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPERIMENT 3: GRU with CBOW Embeddings - Training CBOW\n",
      "============================================================\n",
      "âœ“ Using existing CBOWEmbedding module\n",
      "Training CBOW Word2Vec embeddings...\n",
      "CBOW training complete\n",
      "Vocabulary size: 3985\n",
      "Embedding dimension: 100\n",
      "âœ“ CBOW embedding matrix shape: (6417, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT 3: GRU with CBOW Embeddings - Training CBOW\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get word_index from tokenizer\n",
    "word_index = tokenizer_tfidf.word_index\n",
    "\n",
    "try:\n",
    "    from embeddings.embedding_cbow import CBOWEmbedding\n",
    "    print(\"âœ“ Using existing CBOWEmbedding module\")\n",
    "    \n",
    "    # Initialize CBOW\n",
    "    cbow = CBOWEmbedding(vector_size=100, window=5, min_count=2)\n",
    "    \n",
    "    # Train on all text\n",
    "    cbow.train(all_texts)\n",
    "    \n",
    "    # Get embedding matrix\n",
    "    embedding_matrix_cbow = cbow.get_embedding_matrix(word_index)\n",
    "    print(f\"âœ“ CBOW embedding matrix shape: {embedding_matrix_cbow.shape}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"âš ï¸ CBOWEmbedding module not found, using Word2Vec\")\n",
    "    \n",
    "    # Train Word2Vec CBOW model\n",
    "    sentences = [text.split() for text in all_texts]\n",
    "\n",
    "    cbow_model = Word2Vec(\n",
    "        sentences=sentences,\n",
    "        vector_size=100,\n",
    "        window=5,\n",
    "        min_count=2,\n",
    "        sg=0,  # sg=0 for CBOW\n",
    "        workers=4,\n",
    "        seed=SEED\n",
    "    )\n",
    "\n",
    "    # Create embedding matrix\n",
    "    embedding_matrix_cbow = np.zeros((vocab_size, embedding_dim))\n",
    "    \n",
    "    for word, idx in word_index.items():\n",
    "        if idx < vocab_size:\n",
    "            if word in cbow_model.wv:\n",
    "                embedding_matrix_cbow[idx] = cbow_model.wv[word]\n",
    "            else:\n",
    "                # Initialize with small random values\n",
    "                embedding_matrix_cbow[idx] = np.random.normal(scale=0.1, size=(embedding_dim,))\n",
    "    \n",
    "    print(f\"âœ“ CBOW embedding matrix shape: {embedding_matrix_cbow.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e328cf5",
   "metadata": {},
   "source": [
    "### 9.2 Train GRU with CBOW Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88ef54fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training GRU with CBOW embeddings...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">641,700</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">176,640</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">296,448</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       â”‚       \u001b[38;5;34m641,700\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_8 (\u001b[38;5;33mBidirectional\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚       \u001b[38;5;34m176,640\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_9 (\u001b[38;5;33mBidirectional\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚       \u001b[38;5;34m296,448\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m16,448\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m65\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,131,301</span> (4.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,131,301\u001b[0m (4.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">489,601</span> (1.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m489,601\u001b[0m (1.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">641,700</span> (2.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m641,700\u001b[0m (2.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.8482 - loss: 0.4559"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 187ms/step - accuracy: 0.8615 - loss: 0.4252 - val_accuracy: 0.8655 - val_loss: 0.4047\n",
      "Epoch 2/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 186ms/step - accuracy: 0.8659 - loss: 0.3914 - val_accuracy: 0.8655 - val_loss: 0.3247\n",
      "Epoch 3/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 256ms/step - accuracy: 0.8659 - loss: 0.3293 - val_accuracy: 0.8655 - val_loss: 0.3225\n",
      "Epoch 4/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 258ms/step - accuracy: 0.8674 - loss: 0.3221 - val_accuracy: 0.8655 - val_loss: 0.3165\n",
      "Epoch 5/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 253ms/step - accuracy: 0.8656 - loss: 0.3244 - val_accuracy: 0.8655 - val_loss: 0.3193\n",
      "Epoch 6/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 266ms/step - accuracy: 0.8659 - loss: 0.3176 - val_accuracy: 0.8655 - val_loss: 0.3253\n",
      "Epoch 7/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 260ms/step - accuracy: 0.8659 - loss: 0.3068 - val_accuracy: 0.8655 - val_loss: 0.3085\n",
      "Epoch 8/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 270ms/step - accuracy: 0.8659 - loss: 0.3067 - val_accuracy: 0.8655 - val_loss: 0.3053\n",
      "Epoch 9/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 278ms/step - accuracy: 0.8648 - loss: 0.2960 - val_accuracy: 0.8655 - val_loss: 0.3064\n",
      "Epoch 10/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 274ms/step - accuracy: 0.8654 - loss: 0.3024 - val_accuracy: 0.8655 - val_loss: 0.2996\n",
      "Epoch 11/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 263ms/step - accuracy: 0.8695 - loss: 0.2916 - val_accuracy: 0.8655 - val_loss: 0.2990\n",
      "Epoch 12/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 271ms/step - accuracy: 0.8656 - loss: 0.3006 - val_accuracy: 0.8655 - val_loss: 0.2889\n",
      "Epoch 13/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.8689 - loss: 0.2699"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 279ms/step - accuracy: 0.8668 - loss: 0.2771 - val_accuracy: 0.8717 - val_loss: 0.2847\n",
      "Epoch 14/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.8750 - loss: 0.2741"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 267ms/step - accuracy: 0.8728 - loss: 0.2769 - val_accuracy: 0.9274 - val_loss: 0.2449\n",
      "Epoch 15/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.8875 - loss: 0.2647"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 255ms/step - accuracy: 0.8833 - loss: 0.2750 - val_accuracy: 0.9336 - val_loss: 0.2313\n"
     ]
    }
   ],
   "source": [
    "# Create model with CBOW embeddings\n",
    "model_cbow = create_gru_model(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_matrix_cbow.shape[1],\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=num_layers,\n",
    "    dropout_rate=dropout_rate,\n",
    "    max_len=max_len,\n",
    "    embedding_matrix=embedding_matrix_cbow\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "model_cbow.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "callbacks_cbow = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model_cbow.h5', monitor='val_accuracy', \n",
    "                    save_best_only=True, mode='max')\n",
    "]\n",
    "\n",
    "print(\"\\n Training GRU with CBOW embeddings...\")\n",
    "print(model_cbow.summary())\n",
    "\n",
    "# Train model\n",
    "history_cbow = model_cbow.fit(\n",
    "    X_train_seq, y_train,\n",
    "    validation_data=(X_val_seq, y_val),\n",
    "    epochs=15,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks_cbow,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca31de2e",
   "metadata": {},
   "source": [
    "### 9.3 Evaluate CBOW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "141639de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š CBOW Model - Test Results:\n",
      "Accuracy:  0.9417\n",
      "F1 Score:  0.7303\n",
      "Precision: 0.9565\n",
      "Recall:    0.5906\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib_inline'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Confusion matrix\u001b[39;00m\n\u001b[32m     18\u001b[39m cm_cbow = confusion_matrix(y_test, preds_cbow)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigsize\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m sns.heatmap(cm_cbow, annot=\u001b[38;5;28;01mTrue\u001b[39;00m, fmt=\u001b[33m'\u001b[39m\u001b[33md\u001b[39m\u001b[33m'\u001b[39m, cmap=\u001b[33m'\u001b[39m\u001b[33mOranges\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     21\u001b[39m             xticklabels=[\u001b[33m'\u001b[39m\u001b[33mHam\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mSpam\u001b[39m\u001b[33m'\u001b[39m], yticklabels=[\u001b[33m'\u001b[39m\u001b[33mHam\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mSpam\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     22\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mConfusion Matrix - GRU with CBOW\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/text-classification-groupwork-ObVFzkD4/lib/python3.12/site-packages/matplotlib/pyplot.py:1041\u001b[39m, in \u001b[36mfigure\u001b[39m\u001b[34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, clear, **kwargs)\u001b[39m\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(allnums) == max_open_warning >= \u001b[32m1\u001b[39m:\n\u001b[32m   1032\u001b[39m     _api.warn_external(\n\u001b[32m   1033\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMore than \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_open_warning\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m figures have been opened. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1034\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFigures created through the pyplot interface \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1038\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConsider using `matplotlib.pyplot.close()`.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1039\u001b[39m         \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1041\u001b[39m manager = \u001b[43mnew_figure_manager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfigsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1043\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframeon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframeon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[43m    \u001b[49m\u001b[43mFigureClass\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFigureClass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1045\u001b[39m fig = manager.canvas.figure\n\u001b[32m   1046\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fig_label:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/text-classification-groupwork-ObVFzkD4/lib/python3.12/site-packages/matplotlib/pyplot.py:550\u001b[39m, in \u001b[36mnew_figure_manager\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_figure_manager\u001b[39m(*args, **kwargs):\n\u001b[32m    549\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a new figure manager instance.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m     \u001b[43m_warn_if_gui_out_of_main_thread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_backend_mod().new_figure_manager(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/text-classification-groupwork-ObVFzkD4/lib/python3.12/site-packages/matplotlib/pyplot.py:527\u001b[39m, in \u001b[36m_warn_if_gui_out_of_main_thread\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_warn_if_gui_out_of_main_thread\u001b[39m() -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    526\u001b[39m     warn = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m527\u001b[39m     canvas_class = cast(\u001b[38;5;28mtype\u001b[39m[FigureCanvasBase], \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.FigureCanvas)\n\u001b[32m    528\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m canvas_class.required_interactive_framework:\n\u001b[32m    529\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(threading, \u001b[33m'\u001b[39m\u001b[33mget_native_id\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    530\u001b[39m             \u001b[38;5;66;03m# This compares native thread ids because even if Python-level\u001b[39;00m\n\u001b[32m    531\u001b[39m             \u001b[38;5;66;03m# Thread objects match, the underlying OS thread (which is what\u001b[39;00m\n\u001b[32m    532\u001b[39m             \u001b[38;5;66;03m# really matters) may be different on Python implementations with\u001b[39;00m\n\u001b[32m    533\u001b[39m             \u001b[38;5;66;03m# green threads.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/text-classification-groupwork-ObVFzkD4/lib/python3.12/site-packages/matplotlib/pyplot.py:368\u001b[39m, in \u001b[36m_get_backend_mod\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    360\u001b[39m \u001b[33;03mEnsure that a backend is selected and return it.\u001b[39;00m\n\u001b[32m    361\u001b[39m \n\u001b[32m    362\u001b[39m \u001b[33;03mThis is currently private, but may be made public in the future.\u001b[39;00m\n\u001b[32m    363\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _backend_mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    365\u001b[39m     \u001b[38;5;66;03m# Use rcParams._get(\"backend\") to avoid going through the fallback\u001b[39;00m\n\u001b[32m    366\u001b[39m     \u001b[38;5;66;03m# logic (which will (re)import pyplot and then call switch_backend if\u001b[39;00m\n\u001b[32m    367\u001b[39m     \u001b[38;5;66;03m# we need to resolve the auto sentinel)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m     \u001b[43mswitch_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrcParams\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackend\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[38;5;28mtype\u001b[39m[matplotlib.backend_bases._Backend], _backend_mod)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/text-classification-groupwork-ObVFzkD4/lib/python3.12/site-packages/matplotlib/pyplot.py:424\u001b[39m, in \u001b[36mswitch_backend\u001b[39m\u001b[34m(newbackend)\u001b[39m\n\u001b[32m    421\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    422\u001b[39m old_backend = rcParams._get(\u001b[33m'\u001b[39m\u001b[33mbackend\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# get without triggering backend resolution\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m module = \u001b[43mbackend_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_backend_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m canvas_class = module.FigureCanvas\n\u001b[32m    427\u001b[39m required_framework = canvas_class.required_interactive_framework\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/text-classification-groupwork-ObVFzkD4/lib/python3.12/site-packages/matplotlib/backends/registry.py:317\u001b[39m, in \u001b[36mBackendRegistry.load_backend_module\u001b[39m\u001b[34m(self, backend)\u001b[39m\n\u001b[32m    303\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    304\u001b[39m \u001b[33;03mLoad and return the module containing the specified backend.\u001b[39;00m\n\u001b[32m    305\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    314\u001b[39m \u001b[33;03m    Module containing backend.\u001b[39;00m\n\u001b[32m    315\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    316\u001b[39m module_name = \u001b[38;5;28mself\u001b[39m._backend_module_name(backend)\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/importlib/__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     88\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1310\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:488\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1324\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib_inline'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Evaluate on test set\n",
    "test_metrics_cbow, preds_cbow = evaluate_model(model_cbow, X_test_seq, y_test)\n",
    "\n",
    "print(\"\\nğŸ“Š CBOW Model - Test Results:\")\n",
    "print(f\"Accuracy:  {test_metrics_cbow['accuracy']:.4f}\")\n",
    "print(f\"F1 Score:  {test_metrics_cbow['f1']:.4f}\")\n",
    "print(f\"Precision: {test_metrics_cbow['precision']:.4f}\")\n",
    "print(f\"Recall:    {test_metrics_cbow['recall']:.4f}\")\n",
    "\n",
    "# Save results\n",
    "results_cbow = {\n",
    "    'embedding': 'CBOW',\n",
    "    'test_metrics': test_metrics_cbow,\n",
    "    'train_history': history_cbow.history\n",
    "}\n",
    "\n",
    "# Confusion matrix\n",
    "cm_cbow = confusion_matrix(y_test, preds_cbow)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_cbow, annot=True, fmt='d', cmap='Oranges',\n",
    "            xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "plt.title('Confusion Matrix - GRU with CBOW')\n",
    "plt.savefig('../results/figures/gru_cbow_confusion.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aabbe5",
   "metadata": {},
   "source": [
    "## 10. Comparison of All Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "881713a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMPARISON OF ALL EMBEDDINGS\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results_skipgram' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Create comparison table\u001b[39;00m\n\u001b[32m      6\u001b[39m comparison_data = []\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m results \u001b[38;5;129;01min\u001b[39;00m [results_tfidf, \u001b[43mresults_skipgram\u001b[49m, results_cbow]:\n\u001b[32m      8\u001b[39m     row = {\n\u001b[32m      9\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEmbedding\u001b[39m\u001b[33m'\u001b[39m: results[\u001b[33m'\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     10\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAccuracy\u001b[39m\u001b[33m'\u001b[39m: results[\u001b[33m'\u001b[39m\u001b[33mtest_metrics\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mRecall\u001b[39m\u001b[33m'\u001b[39m: results[\u001b[33m'\u001b[39m\u001b[33mtest_metrics\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mrecall\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     14\u001b[39m     }\n\u001b[32m     15\u001b[39m     comparison_data.append(row)\n",
      "\u001b[31mNameError\u001b[39m: name 'results_skipgram' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPARISON OF ALL EMBEDDINGS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create comparison table\n",
    "comparison_data = []\n",
    "for results in [results_tfidf, results_skipgram, results_cbow]:\n",
    "    row = {\n",
    "        'Embedding': results['embedding'],\n",
    "        'Accuracy': results['test_metrics']['accuracy'],\n",
    "        'F1 Score': results['test_metrics']['f1'],\n",
    "        'Precision': results['test_metrics']['precision'],\n",
    "        'Recall': results['test_metrics']['recall']\n",
    "    }\n",
    "    comparison_data.append(row)\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nğŸ“ˆ Performance Comparison:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Save comparison\n",
    "comparison_df.to_csv('../results/tables/gru_comparison.csv', index=False)\n",
    "print(\"\\n Comparison saved to: ../results/tables/gru_comparison.csv\")\n",
    "\n",
    "# Visualize comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.2\n",
    "\n",
    "plt.bar(x - width, comparison_df['Accuracy'], width, label='Accuracy', alpha=0.8)\n",
    "plt.bar(x, comparison_df['F1 Score'], width, label='F1 Score', alpha=0.8)\n",
    "plt.bar(x + width, comparison_df['Precision'], width, label='Precision', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Embedding Type')\n",
    "plt.ylabel('Score')\n",
    "plt.title('GRU Performance with Different Embeddings')\n",
    "plt.xticks(x, comparison_df['Embedding'])\n",
    "plt.legend()\n",
    "plt.ylim(0.8, 1.0)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (acc, f1, prec) in enumerate(zip(comparison_df['Accuracy'], \n",
    "                                        comparison_df['F1 Score'], \n",
    "                                        comparison_df['Precision'])):\n",
    "    plt.text(i - width, acc + 0.01, f'{acc:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    plt.text(i, f1 + 0.01, f'{f1:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    plt.text(i + width, prec + 0.01, f'{prec:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/gru_embedding_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cfe016",
   "metadata": {},
   "source": [
    "## 11. Training Curves Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2aa20b8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib_inline'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m fig, axes = \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubplots\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Loss curves\u001b[39;00m\n\u001b[32m      4\u001b[39m embeddings = [\u001b[33m'\u001b[39m\u001b[33mTF-IDF\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mSkip-gram\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCBOW\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/text-classification-groupwork-ObVFzkD4/lib/python3.12/site-packages/matplotlib/pyplot.py:1776\u001b[39m, in \u001b[36msubplots\u001b[39m\u001b[34m(nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw, **fig_kw)\u001b[39m\n\u001b[32m   1621\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msubplots\u001b[39m(\n\u001b[32m   1622\u001b[39m     nrows: \u001b[38;5;28mint\u001b[39m = \u001b[32m1\u001b[39m, ncols: \u001b[38;5;28mint\u001b[39m = \u001b[32m1\u001b[39m, *,\n\u001b[32m   1623\u001b[39m     sharex: \u001b[38;5;28mbool\u001b[39m | Literal[\u001b[33m\"\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mall\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrow\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcol\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1630\u001b[39m     **fig_kw\n\u001b[32m   1631\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[Figure, Any]:\n\u001b[32m   1632\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1633\u001b[39m \u001b[33;03m    Create a figure and a set of subplots.\u001b[39;00m\n\u001b[32m   1634\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1774\u001b[39m \n\u001b[32m   1775\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     fig = \u001b[43mfigure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfig_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1777\u001b[39m     axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,\n\u001b[32m   1778\u001b[39m                        squeeze=squeeze, subplot_kw=subplot_kw,\n\u001b[32m   1779\u001b[39m                        gridspec_kw=gridspec_kw, height_ratios=height_ratios,\n\u001b[32m   1780\u001b[39m                        width_ratios=width_ratios)\n\u001b[32m   1781\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fig, axs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/text-classification-groupwork-ObVFzkD4/lib/python3.12/site-packages/matplotlib/pyplot.py:1041\u001b[39m, in \u001b[36mfigure\u001b[39m\u001b[34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, clear, **kwargs)\u001b[39m\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(allnums) == max_open_warning >= \u001b[32m1\u001b[39m:\n\u001b[32m   1032\u001b[39m     _api.warn_external(\n\u001b[32m   1033\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMore than \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_open_warning\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m figures have been opened. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1034\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFigures created through the pyplot interface \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1038\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConsider using `matplotlib.pyplot.close()`.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1039\u001b[39m         \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1041\u001b[39m manager = \u001b[43mnew_figure_manager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfigsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1043\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframeon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframeon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[43m    \u001b[49m\u001b[43mFigureClass\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFigureClass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1045\u001b[39m fig = manager.canvas.figure\n\u001b[32m   1046\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fig_label:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/text-classification-groupwork-ObVFzkD4/lib/python3.12/site-packages/matplotlib/pyplot.py:550\u001b[39m, in \u001b[36mnew_figure_manager\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_figure_manager\u001b[39m(*args, **kwargs):\n\u001b[32m    549\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a new figure manager instance.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m     \u001b[43m_warn_if_gui_out_of_main_thread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_backend_mod().new_figure_manager(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/text-classification-groupwork-ObVFzkD4/lib/python3.12/site-packages/matplotlib/pyplot.py:527\u001b[39m, in \u001b[36m_warn_if_gui_out_of_main_thread\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_warn_if_gui_out_of_main_thread\u001b[39m() -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    526\u001b[39m     warn = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m527\u001b[39m     canvas_class = cast(\u001b[38;5;28mtype\u001b[39m[FigureCanvasBase], \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.FigureCanvas)\n\u001b[32m    528\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m canvas_class.required_interactive_framework:\n\u001b[32m    529\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(threading, \u001b[33m'\u001b[39m\u001b[33mget_native_id\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    530\u001b[39m             \u001b[38;5;66;03m# This compares native thread ids because even if Python-level\u001b[39;00m\n\u001b[32m    531\u001b[39m             \u001b[38;5;66;03m# Thread objects match, the underlying OS thread (which is what\u001b[39;00m\n\u001b[32m    532\u001b[39m             \u001b[38;5;66;03m# really matters) may be different on Python implementations with\u001b[39;00m\n\u001b[32m    533\u001b[39m             \u001b[38;5;66;03m# green threads.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/text-classification-groupwork-ObVFzkD4/lib/python3.12/site-packages/matplotlib/pyplot.py:368\u001b[39m, in \u001b[36m_get_backend_mod\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    360\u001b[39m \u001b[33;03mEnsure that a backend is selected and return it.\u001b[39;00m\n\u001b[32m    361\u001b[39m \n\u001b[32m    362\u001b[39m \u001b[33;03mThis is currently private, but may be made public in the future.\u001b[39;00m\n\u001b[32m    363\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _backend_mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    365\u001b[39m     \u001b[38;5;66;03m# Use rcParams._get(\"backend\") to avoid going through the fallback\u001b[39;00m\n\u001b[32m    366\u001b[39m     \u001b[38;5;66;03m# logic (which will (re)import pyplot and then call switch_backend if\u001b[39;00m\n\u001b[32m    367\u001b[39m     \u001b[38;5;66;03m# we need to resolve the auto sentinel)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m     \u001b[43mswitch_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrcParams\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackend\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[38;5;28mtype\u001b[39m[matplotlib.backend_bases._Backend], _backend_mod)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/text-classification-groupwork-ObVFzkD4/lib/python3.12/site-packages/matplotlib/pyplot.py:424\u001b[39m, in \u001b[36mswitch_backend\u001b[39m\u001b[34m(newbackend)\u001b[39m\n\u001b[32m    421\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    422\u001b[39m old_backend = rcParams._get(\u001b[33m'\u001b[39m\u001b[33mbackend\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# get without triggering backend resolution\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m module = \u001b[43mbackend_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_backend_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m canvas_class = module.FigureCanvas\n\u001b[32m    427\u001b[39m required_framework = canvas_class.required_interactive_framework\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/text-classification-groupwork-ObVFzkD4/lib/python3.12/site-packages/matplotlib/backends/registry.py:317\u001b[39m, in \u001b[36mBackendRegistry.load_backend_module\u001b[39m\u001b[34m(self, backend)\u001b[39m\n\u001b[32m    303\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    304\u001b[39m \u001b[33;03mLoad and return the module containing the specified backend.\u001b[39;00m\n\u001b[32m    305\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    314\u001b[39m \u001b[33;03m    Module containing backend.\u001b[39;00m\n\u001b[32m    315\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    316\u001b[39m module_name = \u001b[38;5;28mself\u001b[39m._backend_module_name(backend)\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/importlib/__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     88\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1310\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:488\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1324\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib_inline'"
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "# Loss curves\n",
    "embeddings = ['TF-IDF', 'Skip-gram', 'CBOW']\n",
    "histories = [history_tfidf, history_skipgram, history_cbow]\n",
    "\n",
    "for i, (embedding, history) in enumerate(zip(embeddings, histories)):\n",
    "    axes[0, i].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "    axes[0, i].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "    axes[0, i].set_title(f'{embedding} - Loss')\n",
    "    axes[0, i].set_xlabel('Epoch')\n",
    "    axes[0, i].set_ylabel('Loss')\n",
    "    axes[0, i].legend()\n",
    "    axes[0, i].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curves\n",
    "for i, (embedding, history) in enumerate(zip(embeddings, histories)):\n",
    "    axes[1, i].plot(history.history['accuracy'], label='Train Acc', linewidth=2)\n",
    "    axes[1, i].plot(history.history['val_accuracy'], label='Val Acc', linewidth=2)\n",
    "    axes[1, i].set_title(f'{embedding} - Accuracy')\n",
    "    axes[1, i].set_xlabel('Epoch')\n",
    "    axes[1, i].set_ylabel('Accuracy')\n",
    "    axes[1, i].legend()\n",
    "    axes[1, i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/gru_training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9e1ea1",
   "metadata": {},
   "source": [
    "## 12. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db17543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ERROR ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Collect misclassified samples\n",
    "errors = []\n",
    "for i, (text, true_label, pred_tfidf, pred_sg, pred_cbow) in enumerate(zip(\n",
    "    X_test[:100],  # First 100 test samples\n",
    "    y_test[:100],\n",
    "    preds_tfidf[:100],\n",
    "    preds_sg[:100],\n",
    "    preds_cbow[:100]\n",
    ")):\n",
    "    if not (true_label == pred_tfidf == pred_sg == pred_cbow):\n",
    "        errors.append({\n",
    "            'text': text[:50] + '...' if len(text) > 50 else text,\n",
    "            'true': 'spam' if true_label == 1 else 'ham',\n",
    "            'tfidf_pred': 'spam' if pred_tfidf == 1 else 'ham',\n",
    "            'skipgram_pred': 'spam' if pred_sg == 1 else 'ham',\n",
    "            'cbow_pred': 'spam' if pred_cbow == 1 else 'ham',\n",
    "            'all_agree': (pred_tfidf == pred_sg == pred_cbow)\n",
    "        })\n",
    "\n",
    "errors_df = pd.DataFrame(errors)\n",
    "print(f\"\\nFound {len(errors)} misclassified samples in first 100 test examples\")\n",
    "\n",
    "if len(errors) > 0:\n",
    "    print(\"\\nğŸ” Sample Misclassifications:\")\n",
    "    print(errors_df.head().to_string(index=False))\n",
    "    \n",
    "    # Save error analysis\n",
    "    errors_df.to_csv('../results/tables/gru_error_analysis.csv', index=False)\n",
    "    print(\"\\n Error analysis saved to: ../results/tables/gru_error_analysis.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0592526",
   "metadata": {},
   "source": [
    "## 13. Summary and Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea24278",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TextCleaner' from 'preprocessing.clean_text' (/Users/sola/text-classification-groupwork/notebooks/../preprocessing/clean_text.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m sys.path.append(\u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Import existing modules\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclean_text\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TextCleaner\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtokenize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tokenizer\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msplit_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataSplitter\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'TextCleaner' from 'preprocessing.clean_text' (/Users/sola/text-classification-groupwork/notebooks/../preprocessing/clean_text.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Find best performing model\n",
    "best_model = max([results_tfidf, results_skipgram, results_cbow], \n",
    "                 key=lambda x: x['test_metrics']['f1'])\n",
    "\n",
    "print(f\"\\n Best Performing Embedding: {best_model['embedding']}\")\n",
    "print(f\"   F1 Score: {best_model['test_metrics']['f1']:.4f}\")\n",
    "print(f\"   Accuracy: {best_model['test_metrics']['accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\n Key Observations:\")\n",
    "print(\"1. All embeddings achieved high performance (>0.95 F1)\")\n",
    "print(\"2. [Your observation about which embedding worked best]\")\n",
    "print(\"3. [Any patterns in misclassifications]\")\n",
    "print(\"4. [Training time/convergence observations]\")\n",
    "\n",
    "print(\"\\n Files Generated:\")\n",
    "print(\"  Results:\")\n",
    "print(\"    ../results/tables/gru_comparison.csv\")\n",
    "print(\"    ../results/tables/gru_error_analysis.csv\")\n",
    "print(\"  Figures:\")\n",
    "print(\"    ../results/figures/gru_tfidf_confusion.png\")\n",
    "print(\"    ../results/figures/gru_skipgram_confusion.png\")\n",
    "print(\"    ../results/figures/gru_cbow_confusion.png\")\n",
    "print(\"    ../results/figures/gru_embedding_comparison.png\")\n",
    "print(\"    ../results/figures/gru_training_curves.png\")\n",
    "\n",
    "print(\"\\n GRU EXPERIMENTS COMPLETE!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-classification-groupwork-ObVFzkD4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
